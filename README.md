
# ðŸ§  Intelligent Image Captioning System â€“ BLIP + Fuzzy Logic + Dragonfly Optimization

A powerful **AI-based image captioning system** integrating **BLIP (Bootstrapping Language-Image Pre-training)** with **fuzzy logic evaluation**, **BLEU & BERTScore metrics**, and a **Dragonfly Optimization Algorithm** to generate *high-quality, optimized captions* for both single images and image sequences.

This project uses **Transformer-based vision-language models**, **linguistic evaluation**, and **nature-inspired optimization** to push captioning quality beyond standard deterministic pipelines.

> ðŸŽ“ **Research Project**: Developed as an advanced AI system integrating ML, NLP, fuzzy inference, and evolutionary optimizationâ€”ideal for research, publications, and multimedia analytics.



## ðŸš€ Key Features

* ðŸ–¼ï¸ **Image Captioning using BLIP + Swin Transformer**
* ðŸ¤– **Parameter optimization** using the **Dragonfly Algorithm**
* ðŸ§® **Real evaluation metrics**: BLEU & BERTScore
* fuzzy **Fuzzy Logic Quality System** for robust scoring
* ðŸ“ Sequential captioning for entire **image folders**
* ðŸ”§ Adjustable decoding parameters (beams, temperature, top-k/p)
* âš™ï¸ **Gradio UI** for interactive testing
* ðŸ“Š Automatic comparison of reference vs generated caption
* ðŸ” NLP tokenization + linguistic scoring via NLTK
* âš¡ GPU-accelerated Transformer inference (PyTorch)
* ðŸ”£ Fully automated pipeline from caption â†’ evaluate â†’ optimize â†’ caption


## ðŸ› ï¸ Tech Stack

| Component          | Technology / Libraries                           |
| ------------------ | ------------------------------------------------ |
| **Model**          | BLIP Image Captioning (HuggingFace Transformers) |
| **Optimization**   | Dragonfly Algorithm                              |
| **Evaluation**     | BLEU, BERTScore, Fuzzy Logic                     |
| **NLP**            | NLTK                                             |
| **UI**             | Gradio                                           |
| **Backend Engine** | PyTorch                                          |
| **Math / Logic**   | NumPy, scikit-fuzzy                              |



## âš™ï¸ How It Works

### 1ï¸âƒ£ **Load BLIP Model**

* Pretrained on large-scale vision-language datasets
* Generates initial captions given an image

### 2ï¸âƒ£ **Generate Caption**

Uses configurable decoding parameters:

* `num_beams`
* `max_length`
* `temperature`
* `top_k`, `top_p`

### 3ï¸âƒ£ **Evaluate Caption**

Two complementary metrics:

* **BLEU Score** â€“ syntactic similarity
* **BERTScore** â€“ semantic similarity

### 4ï¸âƒ£ **Fuzzy Logic Quality Estimation**

Inputs:

* BLEU
* Similarity (BERTScore)

Output:

* **Quality score** (0â€“1)

### 5ï¸âƒ£ **Dragonfly Optimization**

Repeatedly:

1. Randomly sample decoding parameters
2. Generate caption
3. Evaluate & fuzzy-score
4. Keep best parameters

### 6ï¸âƒ£ **Gradio App**

* **Single Image Mode**
* **Folder Sequence Mode**
* Fully interactive captions + evaluations



## ðŸ“‚ Directory Support

Supports:

* Single images
* Entire folders (for video frames, datasets, surveillance data, drone images, etc.)



## ðŸ§ª Testing Workflow

1. Upload an image
2. Provide a *reference caption*
3. System optimizes BLIP parameters
4. Generates the best caption
5. Shows:

   * Optimized params
   * BLEU score
   * BERTScore
   * Fuzzy Quality (%)

For folder mode:

* Upload a zipped/unzipped folder
* Captions are generated for each image sequentially



## ðŸ“¦ Installation & Setup

### Prerequisites

* Python 3.8+
* PyTorch (CPU/GPU)
* Transformers
* scikit-fuzzy
* NLTK
* Gradio

### Install Dependencies

```bash
pip install torch transformers gradio scikit-fuzzy nltk bert-score pillow
```

### Run the App

```bash
python app.py
```

Gradio UI will appear at:

```
http://localhost:7860
```



## ðŸ” Example Output

For each image, you get:

* ðŸ–¼ï¸ **Generated Caption**
* ðŸ”§ **Optimal Parameters**
* ðŸ“Š **BLEU Score**
* ðŸ¤– **BERTScore**
* ðŸ§  **Fuzzy Quality Score**



## ðŸ”® Future Enhancements

* ðŸ§¬ Genetic Algorithm + PSO comparison
* ðŸ“ˆ Visualization dashboards for evaluation metrics
* ðŸ“½ï¸ Video captioning using frame batching
* ðŸŒ API deployment (FastAPI / Flask)
* ðŸ› ï¸ ONNX Runtime acceleration




## ðŸ‘©â€ðŸ’» Author

**Samiksha Walia**
[GitHub](https://github.com/Samiksha-Walia) â€¢ [LinkedIn](https://linkedin.com/in/samiksha-walia)



## â­ Show Your Support

If this project supports your research or learning, â­ the repository and share your experience!

> *A fusion of vision-language models, NLP quality metrics, fuzzy intelligence, and swarm optimizationâ€”designed for next-gen AI captioning systems.*

